## Problem 1

##10.7(a)


**Read the data and change the names of the columns**
```{r}
df = read.table("/Users/naughtyboy35/Desktop/Stat 615/hw1/maintenance")

cols = c("hours", "copiers")

colnames(df) = cols
```

## 1.3.4(c)

**Find the linear regression line as well as its residuals**
```{r}

fit = lm(hours~copiers,df)

residuals = resid(fit)

hist(residuals)
```

**We can see from the histogram that the residuals of the linear regression line is mainly normally distributed**


##1.3.4(d)

**Find the regression line**
```{r}
summary(fit)
```
**Our linear regression function is y_hat = 15.0352*x_hat-0.5802**

**Find the y_hats with the regression line**
```{r}
xi = df$copiers

y_hat = 15.0352 * xi - 0.5802

```


**Plot the residuals with xi**

```{r}
plot(xi, residuals)
```


**Plot the y_hat with the residuals**

```{r}
plot(y_hat, residuals)
```


**The variance of the residuals seem to be constant with the change of Xi and Y_hat, so we can see our assumption that the variance is constant is not violated in this case. Also, we can see that there are potential outliers which fall out of the range of (-15, 15), which is most of where our points lie within.**


## 3.4(h)

**Read the data in R studio, and change the names of the columns**
```{r}
df2 = read.table("/Users/naughtyboy35/Desktop/Stat 615/hw3/dataset3.txt")

cols = c("hours", "copiers", "x2", "x3")

colnames(df2) = cols

```




## Plot the residuals and x2 on a scatterplot ## 
```{r}
plot(df2$x2, residuals, xlab = "x2")
```

**Plot the residuals and x3 on a scatterplot**
```{r}
plot(df2$x3, residuals, xlab = "x3")
```

**Since there is no apparent correlation between x3 and the residuals, we conclude that the model can be improved by including x2**

## 3.4(e)

**Prepare the QQ-line and the normal QQ plot**

```{r}
qqnorm(fit$residuals)
qqline(fit$residuals)
```

**H0: The residuals are normally distributed.  H1: The residuals are not normally distributed**


**Perform the Shapiro-Wilk test**


```{r}
shapiro.test(fit$residuals)
```

**We can see the p-value is 0.4577, which is greater than alpha = 0.1, so we do not reject the null hypothesis H0 at alpha = 0.1, and conclude that the residuals are normally distributed**


## Problem 2 

**Find the lack of fit anova table, and read the f-statistic for the lack of fit**

```{r}
fit.lof = lm(hours ~ as.factor(copiers), data=df2)
anova(fit, fit.lof)
```


**Our hypotheses are H0: The model is reasonable and it doesn't have a lack of fit. Ha: The model is not reasonable, it does have a lack of fit**




**The F-statistic is 0.9676**


**Find the f-statistic with df(df for lack of fit) = 8, df2 = 43(df for the residuals)**
```{r}
qf(0.95,8,43)
```

**f(8,43) = 2.16253**


**We can see that f(8,43) = 2.16253, so F-statistic < f(8,43), so we do not reject H0 at alpha = 0.05**


## Problem 3


## 3.17(a)

**Load the data and change the names**
```{r}
salesgrowth = read.table("/Users/naughtyboy35/Desktop/Stat 615/hw3/salesgrowth.txt")

cols = c("sales", "years")

colnames(salesgrowth) = cols
```

**Plot the variable years with sales**
```{r}
plot(salesgrowth$years, salesgrowth$sales, xlab = "years", ylab = "sales")
```
**Yes, a linear relation appears adequate here**


#  3.17(c)

**Find the y_squared_root from the transformation**
```{r}
y_squared_root = sqrt(salesgrowth$sales)
```

**Find the linear regression from the transformation**
```{r}
fit_sales = lm(y_squared_root ~ salesgrowth$years)
summary(fit_sales)
```

**So the estimated linear regression line is sqrt(sales) = 1.07629 *years + 10.26093**


## 3.17(d)
```{r}
plot(salesgrowth$years, y_squared_root)

abline(fit_sales)
```




**Yes, it seems to be a good fit for the transformed data**



## 3.17(e)
```{r}
plot(salesgrowth$years, fit_sales$residuals)
```

**Obtain the normal qqline and qq-plot**
```{r}
qqnorm(fit_sales$residuals)
qqline(fit_sales$residuals)
```

**We can see that there's a correlation between the fitted values and the residuals, also the residuals are normally distributed for the linear regression line**


## 3.17(f)

**We square both sides of the linear regression line, and get sales = (1.07629 *years + 10.26093)^2**

